nohup: ignoring input
Namespace(batch_size=64, dataset_name='MELD', epochs=50, gnn_layers=5, hidden_dim=600, lr=5e-05, mlp_layers=2, modality='ta', tau=1.0)
device: cuda
building model..
building datasets..
train dialogue num:
1038
train utterance num:
9989
building datasets..
dev dialogue num:
114
dev utterance num:
1109
building datasets..
test dialogue num:
280
test utterance num:
2610
==========Epoch: 1 ==============
Epoch: 1, train_loss: 1.5633, valid_waf1: 0.25229698419570923, test_waf1: 0.31268492341041565
==========Epoch: 2 ==============
Epoch: 2, train_loss: 1.1324, valid_waf1: 0.5520688891410828, test_waf1: 0.6005820631980896
==========Epoch: 3 ==============
Epoch: 3, train_loss: 0.8585, valid_waf1: 0.6231793761253357, test_waf1: 0.6415181159973145
==========Epoch: 4 ==============
Epoch: 4, train_loss: 0.7633, valid_waf1: 0.6418299674987793, test_waf1: 0.6498979926109314
==========Epoch: 5 ==============
Epoch: 5, train_loss: 0.7333, valid_waf1: 0.6303637623786926, test_waf1: 0.6489906907081604
==========Epoch: 6 ==============
Epoch: 6, train_loss: 0.7225, valid_waf1: 0.6341946721076965, test_waf1: 0.6569503545761108
==========Epoch: 7 ==============
Epoch: 7, train_loss: 0.7096, valid_waf1: 0.6375202536582947, test_waf1: 0.6569168567657471
==========Epoch: 8 ==============
Epoch: 8, train_loss: 0.7089, valid_waf1: 0.6441161036491394, test_waf1: 0.6540228724479675
==========Epoch: 9 ==============
Epoch: 9, train_loss: 0.7001, valid_waf1: 0.6386275887489319, test_waf1: 0.6578957438468933
==========Epoch: 10 ==============
Epoch: 10, train_loss: 0.7029, valid_waf1: 0.6424942016601562, test_waf1: 0.6571750044822693
==========Epoch: 11 ==============
Epoch: 11, train_loss: 0.6975, valid_waf1: 0.6451978087425232, test_waf1: 0.6614671349525452
==========Epoch: 12 ==============
Epoch: 12, train_loss: 0.6941, valid_waf1: 0.6415007710456848, test_waf1: 0.6623429656028748
==========Epoch: 13 ==============
Epoch: 13, train_loss: 0.6903, valid_waf1: 0.646634042263031, test_waf1: 0.6564685702323914
==========Epoch: 14 ==============
Epoch: 14, train_loss: 0.6894, valid_waf1: 0.6439834833145142, test_waf1: 0.6636131405830383
==========Epoch: 15 ==============
Epoch: 15, train_loss: 0.6877, valid_waf1: 0.6508315205574036, test_waf1: 0.6631338596343994
==========Epoch: 16 ==============
Epoch: 16, train_loss: 0.6766, valid_waf1: 0.6401485204696655, test_waf1: 0.6583392024040222
==========Epoch: 17 ==============
Epoch: 17, train_loss: 0.6756, valid_waf1: 0.6487830877304077, test_waf1: 0.6653356552124023
==========Epoch: 18 ==============
Epoch: 18, train_loss: 0.6814, valid_waf1: 0.6644131541252136, test_waf1: 0.6687222719192505
==========Epoch: 19 ==============
Epoch: 19, train_loss: 0.6745, valid_waf1: 0.6441118121147156, test_waf1: 0.6692368984222412
==========Epoch: 20 ==============
Epoch: 20, train_loss: 0.6726, valid_waf1: 0.6567152142524719, test_waf1: 0.6689362525939941
==========Epoch: 21 ==============
Epoch: 21, train_loss: 0.6838, valid_waf1: 0.650907576084137, test_waf1: 0.6677912473678589
==========Epoch: 22 ==============
Epoch: 22, train_loss: 0.6694, valid_waf1: 0.6637144684791565, test_waf1: 0.6726127862930298
==========Epoch: 23 ==============
Epoch: 23, train_loss: 0.666, valid_waf1: 0.6587687134742737, test_waf1: 0.6650754809379578
==========Epoch: 24 ==============
Epoch: 24, train_loss: 0.6664, valid_waf1: 0.6606431603431702, test_waf1: 0.6677773594856262
==========Epoch: 25 ==============
Epoch: 25, train_loss: 0.666, valid_waf1: 0.6654921174049377, test_waf1: 0.668480396270752
==========Epoch: 26 ==============
Epoch: 26, train_loss: 0.6593, valid_waf1: 0.6664251685142517, test_waf1: 0.6714938879013062
==========Epoch: 27 ==============
Epoch: 27, train_loss: 0.6607, valid_waf1: 0.6582571268081665, test_waf1: 0.6657789349555969
==========Epoch: 28 ==============
Epoch: 28, train_loss: 0.6602, valid_waf1: 0.6570221185684204, test_waf1: 0.6659482717514038
==========Epoch: 29 ==============
Epoch: 29, train_loss: 0.6569, valid_waf1: 0.6647804975509644, test_waf1: 0.6724771857261658
==========Epoch: 30 ==============
Epoch: 30, train_loss: 0.6554, valid_waf1: 0.6571347117424011, test_waf1: 0.6670668721199036
==========Epoch: 31 ==============
Epoch: 31, train_loss: 0.6497, valid_waf1: 0.6581742763519287, test_waf1: 0.6659464836120605
==========Epoch: 32 ==============
Epoch: 32, train_loss: 0.6539, valid_waf1: 0.6685367226600647, test_waf1: 0.6671538352966309
==========Epoch: 33 ==============
Epoch: 33, train_loss: 0.6553, valid_waf1: 0.6653860807418823, test_waf1: 0.6697875261306763
==========Epoch: 34 ==============
Epoch: 34, train_loss: 0.6478, valid_waf1: 0.6565331816673279, test_waf1: 0.6610044240951538
==========Epoch: 35 ==============
Epoch: 35, train_loss: 0.6481, valid_waf1: 0.6634384989738464, test_waf1: 0.6721928119659424
==========Epoch: 36 ==============
Epoch: 36, train_loss: 0.651, valid_waf1: 0.6635839343070984, test_waf1: 0.6674025654792786
==========Epoch: 37 ==============
Epoch: 37, train_loss: 0.6515, valid_waf1: 0.6595383286476135, test_waf1: 0.66851407289505
==========Epoch: 38 ==============
Epoch: 38, train_loss: 0.6512, valid_waf1: 0.6656014919281006, test_waf1: 0.6701262593269348
==========Epoch: 39 ==============
Epoch: 39, train_loss: 0.6389, valid_waf1: 0.6616182327270508, test_waf1: 0.6685733199119568
==========Epoch: 40 ==============
Epoch: 40, train_loss: 0.6443, valid_waf1: 0.6609559059143066, test_waf1: 0.6676794290542603
==========Epoch: 41 ==============
Epoch: 41, train_loss: 0.6455, valid_waf1: 0.6627736687660217, test_waf1: 0.6717232465744019
==========Epoch: 42 ==============
Epoch: 42, train_loss: 0.6397, valid_waf1: 0.6541581153869629, test_waf1: 0.6689164638519287
==========Epoch: 43 ==============
Epoch: 43, train_loss: 0.6411, valid_waf1: 0.6620266437530518, test_waf1: 0.6688689589500427
==========Epoch: 44 ==============
Epoch: 44, train_loss: 0.6437, valid_waf1: 0.6587565541267395, test_waf1: 0.6694079041481018
==========Epoch: 45 ==============
Epoch: 45, train_loss: 0.6349, valid_waf1: 0.6612493395805359, test_waf1: 0.6700974106788635
==========Epoch: 46 ==============
Epoch: 46, train_loss: 0.636, valid_waf1: 0.6682044863700867, test_waf1: 0.6751011610031128
==========Epoch: 47 ==============
Epoch: 47, train_loss: 0.6387, valid_waf1: 0.6607505679130554, test_waf1: 0.6724662780761719
==========Epoch: 48 ==============
Epoch: 48, train_loss: 0.6347, valid_waf1: 0.669261634349823, test_waf1: 0.6749923825263977
==========Epoch: 49 ==============
Epoch: 49, train_loss: 0.6341, valid_waf1: 0.659904420375824, test_waf1: 0.6760603189468384
==========Epoch: 50 ==============
Epoch: 50, train_loss: 0.6283, valid_waf1: 0.6585632562637329, test_waf1: 0.6748344898223877
The best dev set WA.F1:0.669261634349823
************final performance on test set************
The corresponding test set WA.F1 when the dev set WA.F1 is the best:0.6749923825263977
finish training!
