nohup: ignoring input
Namespace(batch_size=64, dataset_name='MELD', epochs=50, gnn_layers=5, hidden_dim=600, lr=5e-05, mlp_layers=2, modality='ta', tau=1.0)
device: cuda
building model..
building datasets..
train dialogue num:
1038
train utterance num:
9989
building datasets..
dev dialogue num:
114
dev utterance num:
1109
building datasets..
test dialogue num:
280
test utterance num:
2610
==========Epoch: 1 ==============
Epoch: 1, train_loss: 1.5633, valid_waf1: 0.25229698419570923, test_waf1: 0.31268492341041565
==========Epoch: 2 ==============
Epoch: 2, train_loss: 1.1324, valid_waf1: 0.5520688891410828, test_waf1: 0.6005820631980896
==========Epoch: 3 ==============
Epoch: 3, train_loss: 0.8585, valid_waf1: 0.6231793761253357, test_waf1: 0.6415181159973145
==========Epoch: 4 ==============
Epoch: 4, train_loss: 0.7633, valid_waf1: 0.6418299674987793, test_waf1: 0.6498979926109314
==========Epoch: 5 ==============
Epoch: 5, train_loss: 0.7333, valid_waf1: 0.6303637623786926, test_waf1: 0.6489906907081604
==========Epoch: 6 ==============
Epoch: 6, train_loss: 0.7225, valid_waf1: 0.6341946721076965, test_waf1: 0.6569503545761108
==========Epoch: 7 ==============
Epoch: 7, train_loss: 0.7095, valid_waf1: 0.6375415325164795, test_waf1: 0.6565048694610596
==========Epoch: 8 ==============
Epoch: 8, train_loss: 0.7089, valid_waf1: 0.6433711647987366, test_waf1: 0.6544406414031982
==========Epoch: 9 ==============
Epoch: 9, train_loss: 0.7, valid_waf1: 0.6386275887489319, test_waf1: 0.6583077907562256
==========Epoch: 10 ==============
Epoch: 10, train_loss: 0.7029, valid_waf1: 0.6426460146903992, test_waf1: 0.6576294898986816
==========Epoch: 11 ==============
Epoch: 11, train_loss: 0.6975, valid_waf1: 0.6451978087425232, test_waf1: 0.6613523960113525
==========Epoch: 12 ==============
Epoch: 12, train_loss: 0.6942, valid_waf1: 0.6415007710456848, test_waf1: 0.6627179384231567
==========Epoch: 13 ==============
Epoch: 13, train_loss: 0.6902, valid_waf1: 0.6456769704818726, test_waf1: 0.655590295791626
==========Epoch: 14 ==============
Epoch: 14, train_loss: 0.6894, valid_waf1: 0.6450764536857605, test_waf1: 0.6636589169502258
==========Epoch: 15 ==============
Epoch: 15, train_loss: 0.6878, valid_waf1: 0.6508315205574036, test_waf1: 0.6631835699081421
==========Epoch: 16 ==============
Epoch: 16, train_loss: 0.6766, valid_waf1: 0.6403540968894958, test_waf1: 0.6582069396972656
==========Epoch: 17 ==============
Epoch: 17, train_loss: 0.6755, valid_waf1: 0.6491810083389282, test_waf1: 0.6645029187202454
==========Epoch: 18 ==============
Epoch: 18, train_loss: 0.6813, valid_waf1: 0.663037121295929, test_waf1: 0.6676386594772339
==========Epoch: 19 ==============
Epoch: 19, train_loss: 0.6746, valid_waf1: 0.6458877921104431, test_waf1: 0.6684942245483398
==========Epoch: 20 ==============
Epoch: 20, train_loss: 0.6727, valid_waf1: 0.6588239669799805, test_waf1: 0.6686440706253052
==========Epoch: 21 ==============
Epoch: 21, train_loss: 0.6838, valid_waf1: 0.652343213558197, test_waf1: 0.6684510707855225
==========Epoch: 22 ==============
Epoch: 22, train_loss: 0.6694, valid_waf1: 0.6641483306884766, test_waf1: 0.6718280911445618
==========Epoch: 23 ==============
Epoch: 23, train_loss: 0.6659, valid_waf1: 0.6572486758232117, test_waf1: 0.664474368095398
==========Epoch: 24 ==============
Epoch: 24, train_loss: 0.6665, valid_waf1: 0.659881055355072, test_waf1: 0.6670154333114624
==========Epoch: 25 ==============
Epoch: 25, train_loss: 0.666, valid_waf1: 0.6626247763633728, test_waf1: 0.6682946085929871
==========Epoch: 26 ==============
Epoch: 26, train_loss: 0.6593, valid_waf1: 0.6659553647041321, test_waf1: 0.6720426082611084
==========Epoch: 27 ==============
Epoch: 27, train_loss: 0.6609, valid_waf1: 0.6591189503669739, test_waf1: 0.6664382219314575
==========Epoch: 28 ==============
Epoch: 28, train_loss: 0.6603, valid_waf1: 0.6552754044532776, test_waf1: 0.6665575504302979
==========Epoch: 29 ==============
Epoch: 29, train_loss: 0.657, valid_waf1: 0.664688766002655, test_waf1: 0.6723660230636597
==========Epoch: 30 ==============
Epoch: 30, train_loss: 0.6556, valid_waf1: 0.6569022536277771, test_waf1: 0.6656401753425598
==========Epoch: 31 ==============
Epoch: 31, train_loss: 0.6496, valid_waf1: 0.6603347063064575, test_waf1: 0.6646665930747986
==========Epoch: 32 ==============
Epoch: 32, train_loss: 0.654, valid_waf1: 0.6703780889511108, test_waf1: 0.6679964661598206
==========Epoch: 33 ==============
Epoch: 33, train_loss: 0.6553, valid_waf1: 0.6653292179107666, test_waf1: 0.6695444583892822
==========Epoch: 34 ==============
Epoch: 34, train_loss: 0.6479, valid_waf1: 0.6557578444480896, test_waf1: 0.662495493888855
==========Epoch: 35 ==============
Epoch: 35, train_loss: 0.6483, valid_waf1: 0.6614243388175964, test_waf1: 0.6736225485801697
==========Epoch: 36 ==============
Epoch: 36, train_loss: 0.6509, valid_waf1: 0.6622936725616455, test_waf1: 0.667041003704071
==========Epoch: 37 ==============
Epoch: 37, train_loss: 0.6516, valid_waf1: 0.6579605340957642, test_waf1: 0.6672858595848083
==========Epoch: 38 ==============
Epoch: 38, train_loss: 0.6516, valid_waf1: 0.666558027267456, test_waf1: 0.6709684729576111
==========Epoch: 39 ==============
Epoch: 39, train_loss: 0.639, valid_waf1: 0.6624698042869568, test_waf1: 0.6688600182533264
==========Epoch: 40 ==============
Epoch: 40, train_loss: 0.6445, valid_waf1: 0.6625290513038635, test_waf1: 0.6679044961929321
==========Epoch: 41 ==============
Epoch: 41, train_loss: 0.6457, valid_waf1: 0.6618743538856506, test_waf1: 0.6708291172981262
==========Epoch: 42 ==============
Epoch: 42, train_loss: 0.6401, valid_waf1: 0.6538392901420593, test_waf1: 0.6684738397598267
==========Epoch: 43 ==============
Epoch: 43, train_loss: 0.6415, valid_waf1: 0.6621012091636658, test_waf1: 0.6700010299682617
==========Epoch: 44 ==============
Epoch: 44, train_loss: 0.644, valid_waf1: 0.6599804162979126, test_waf1: 0.670099139213562
==========Epoch: 45 ==============
Epoch: 45, train_loss: 0.6352, valid_waf1: 0.6581988334655762, test_waf1: 0.6712275743484497
==========Epoch: 46 ==============
Epoch: 46, train_loss: 0.6363, valid_waf1: 0.6675565242767334, test_waf1: 0.6765052676200867
==========Epoch: 47 ==============
Epoch: 47, train_loss: 0.6391, valid_waf1: 0.6598489284515381, test_waf1: 0.6744475960731506
==========Epoch: 48 ==============
Epoch: 48, train_loss: 0.6351, valid_waf1: 0.667384147644043, test_waf1: 0.6758943200111389
==========Epoch: 49 ==============
Epoch: 49, train_loss: 0.6342, valid_waf1: 0.6590564846992493, test_waf1: 0.6798518896102905
==========Epoch: 50 ==============
Epoch: 50, train_loss: 0.6287, valid_waf1: 0.6555523872375488, test_waf1: 0.6757968664169312
The best dev set WA.F1:0.6703780889511108
************final performance on test set************
The corresponding test set WA.F1 when the dev set WA.F1 is the best:0.6679964661598206
finish training!
