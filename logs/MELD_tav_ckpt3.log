nohup: ignoring input
Namespace(batch_size=64, dataset_name='MELD', epochs=50, gnn_layers=5, hidden_dim=600, lr=5e-05, mlp_layers=2, modality='tav', tau=1.0)
device: cuda
building model..
building datasets..
train dialogue num:
1038
train utterance num:
9989
building datasets..
dev dialogue num:
114
dev utterance num:
1109
building datasets..
test dialogue num:
280
test utterance num:
2610
==========Epoch: 1 ==============
Epoch: 1, train_loss: 1.6312, valid_waf1: 0.25229698419570923, test_waf1: 0.31268492341041565
==========Epoch: 2 ==============
Epoch: 2, train_loss: 1.2264, valid_waf1: 0.5268710255622864, test_waf1: 0.5625633597373962
==========Epoch: 3 ==============
Epoch: 3, train_loss: 0.9478, valid_waf1: 0.5964544415473938, test_waf1: 0.6216980814933777
==========Epoch: 4 ==============
Epoch: 4, train_loss: 0.802, valid_waf1: 0.6308645009994507, test_waf1: 0.6488292813301086
==========Epoch: 5 ==============
Epoch: 5, train_loss: 0.7443, valid_waf1: 0.6376854181289673, test_waf1: 0.6554923057556152
==========Epoch: 6 ==============
Epoch: 6, train_loss: 0.7311, valid_waf1: 0.6380304098129272, test_waf1: 0.6540754437446594
==========Epoch: 7 ==============
Epoch: 7, train_loss: 0.7278, valid_waf1: 0.6379995346069336, test_waf1: 0.6549559831619263
==========Epoch: 8 ==============
Epoch: 8, train_loss: 0.7246, valid_waf1: 0.631678581237793, test_waf1: 0.6544169187545776
==========Epoch: 9 ==============
Epoch: 9, train_loss: 0.7197, valid_waf1: 0.6365549564361572, test_waf1: 0.6534309387207031
==========Epoch: 10 ==============
Epoch: 10, train_loss: 0.713, valid_waf1: 0.6369647979736328, test_waf1: 0.6587377786636353
==========Epoch: 11 ==============
Epoch: 11, train_loss: 0.7103, valid_waf1: 0.634602963924408, test_waf1: 0.6532368659973145
==========Epoch: 12 ==============
Epoch: 12, train_loss: 0.7106, valid_waf1: 0.6399731040000916, test_waf1: 0.6613096594810486
==========Epoch: 13 ==============
Epoch: 13, train_loss: 0.7036, valid_waf1: 0.6365221738815308, test_waf1: 0.6665318012237549
==========Epoch: 14 ==============
Epoch: 14, train_loss: 0.6998, valid_waf1: 0.6400584578514099, test_waf1: 0.661220371723175
==========Epoch: 15 ==============
Epoch: 15, train_loss: 0.6974, valid_waf1: 0.6452642679214478, test_waf1: 0.6663506031036377
==========Epoch: 16 ==============
Epoch: 16, train_loss: 0.6887, valid_waf1: 0.6425826549530029, test_waf1: 0.664271354675293
==========Epoch: 17 ==============
Epoch: 17, train_loss: 0.693, valid_waf1: 0.6406205296516418, test_waf1: 0.6585926413536072
==========Epoch: 18 ==============
Epoch: 18, train_loss: 0.6934, valid_waf1: 0.6505963802337646, test_waf1: 0.6689818501472473
==========Epoch: 19 ==============
Epoch: 19, train_loss: 0.6854, valid_waf1: 0.6510189771652222, test_waf1: 0.6649875640869141
==========Epoch: 20 ==============
Epoch: 20, train_loss: 0.6803, valid_waf1: 0.6507250070571899, test_waf1: 0.6699813604354858
==========Epoch: 21 ==============
Epoch: 21, train_loss: 0.6824, valid_waf1: 0.6591935753822327, test_waf1: 0.6710097193717957
==========Epoch: 22 ==============
Epoch: 22, train_loss: 0.6775, valid_waf1: 0.646114706993103, test_waf1: 0.6620402932167053
==========Epoch: 23 ==============
Epoch: 23, train_loss: 0.6772, valid_waf1: 0.6558228135108948, test_waf1: 0.6739778518676758
==========Epoch: 24 ==============
Epoch: 24, train_loss: 0.6736, valid_waf1: 0.6610942482948303, test_waf1: 0.6696862578392029
==========Epoch: 25 ==============
Epoch: 25, train_loss: 0.6735, valid_waf1: 0.655502200126648, test_waf1: 0.6726629734039307
==========Epoch: 26 ==============
Epoch: 26, train_loss: 0.6737, valid_waf1: 0.6489669680595398, test_waf1: 0.6658206582069397
==========Epoch: 27 ==============
Epoch: 27, train_loss: 0.6682, valid_waf1: 0.6500638723373413, test_waf1: 0.6742815375328064
==========Epoch: 28 ==============
Epoch: 28, train_loss: 0.6656, valid_waf1: 0.6626226305961609, test_waf1: 0.6728209853172302
==========Epoch: 29 ==============
Epoch: 29, train_loss: 0.6679, valid_waf1: 0.6628423929214478, test_waf1: 0.6668320298194885
==========Epoch: 30 ==============
Epoch: 30, train_loss: 0.6683, valid_waf1: 0.6565862894058228, test_waf1: 0.6704850196838379
==========Epoch: 31 ==============
Epoch: 31, train_loss: 0.6643, valid_waf1: 0.6567817330360413, test_waf1: 0.6660560965538025
==========Epoch: 32 ==============
Epoch: 32, train_loss: 0.6636, valid_waf1: 0.655781090259552, test_waf1: 0.6664453148841858
==========Epoch: 33 ==============
Epoch: 33, train_loss: 0.6622, valid_waf1: 0.659207284450531, test_waf1: 0.6674267053604126
==========Epoch: 34 ==============
Epoch: 34, train_loss: 0.6608, valid_waf1: 0.6616189479827881, test_waf1: 0.6671322584152222
==========Epoch: 35 ==============
Epoch: 35, train_loss: 0.6576, valid_waf1: 0.6613855361938477, test_waf1: 0.6737978458404541
==========Epoch: 36 ==============
Epoch: 36, train_loss: 0.6557, valid_waf1: 0.6467373371124268, test_waf1: 0.6624011993408203
==========Epoch: 37 ==============
Epoch: 37, train_loss: 0.6553, valid_waf1: 0.6670262217521667, test_waf1: 0.6753539443016052
==========Epoch: 38 ==============
Epoch: 38, train_loss: 0.653, valid_waf1: 0.6622359156608582, test_waf1: 0.6723206043243408
==========Epoch: 39 ==============
Epoch: 39, train_loss: 0.6528, valid_waf1: 0.6630966663360596, test_waf1: 0.6733331084251404
==========Epoch: 40 ==============
Epoch: 40, train_loss: 0.6493, valid_waf1: 0.669809103012085, test_waf1: 0.6798551678657532
==========Epoch: 41 ==============
Epoch: 41, train_loss: 0.6501, valid_waf1: 0.6610831022262573, test_waf1: 0.6742632389068604
==========Epoch: 42 ==============
Epoch: 42, train_loss: 0.646, valid_waf1: 0.6600907444953918, test_waf1: 0.672351062297821
==========Epoch: 43 ==============
Epoch: 43, train_loss: 0.6436, valid_waf1: 0.6634476184844971, test_waf1: 0.671895444393158
==========Epoch: 44 ==============
Epoch: 44, train_loss: 0.6462, valid_waf1: 0.6527987122535706, test_waf1: 0.6704444885253906
==========Epoch: 45 ==============
Epoch: 45, train_loss: 0.6429, valid_waf1: 0.6437247395515442, test_waf1: 0.6595502495765686
==========Epoch: 46 ==============
Epoch: 46, train_loss: 0.6509, valid_waf1: 0.6675912141799927, test_waf1: 0.6754138469696045
==========Epoch: 47 ==============
Epoch: 47, train_loss: 0.6463, valid_waf1: 0.6627388000488281, test_waf1: 0.6786946058273315
==========Epoch: 48 ==============
Epoch: 48, train_loss: 0.6407, valid_waf1: 0.6581135988235474, test_waf1: 0.6756331920623779
==========Epoch: 49 ==============
Epoch: 49, train_loss: 0.6412, valid_waf1: 0.6672703623771667, test_waf1: 0.6771270632743835
==========Epoch: 50 ==============
Epoch: 50, train_loss: 0.6365, valid_waf1: 0.6708292961120605, test_waf1: 0.6823464035987854
The best dev set WA.F1:0.6708292961120605
************final performance on test set************
The corresponding test set WA.F1 when the dev set WA.F1 is the best:0.6823464035987854
finish training!
