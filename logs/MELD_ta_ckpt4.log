nohup: ignoring input
Namespace(batch_size=64, dataset_name='MELD', epochs=50, gnn_layers=5, hidden_dim=600, lr=5e-05, mlp_layers=2, modality='ta', tau=1.0)
device: cuda
building model..
building datasets..
train dialogue num:
1038
train utterance num:
9989
building datasets..
dev dialogue num:
114
dev utterance num:
1109
building datasets..
test dialogue num:
280
test utterance num:
2610
==========Epoch: 1 ==============
Epoch: 1, train_loss: 1.5633, valid_waf1: 0.25229698419570923, test_waf1: 0.31268492341041565
==========Epoch: 2 ==============
Epoch: 2, train_loss: 1.1324, valid_waf1: 0.5520688891410828, test_waf1: 0.6005820631980896
==========Epoch: 3 ==============
Epoch: 3, train_loss: 0.8585, valid_waf1: 0.6231793761253357, test_waf1: 0.6415181159973145
==========Epoch: 4 ==============
Epoch: 4, train_loss: 0.7633, valid_waf1: 0.6418299674987793, test_waf1: 0.6498979926109314
==========Epoch: 5 ==============
Epoch: 5, train_loss: 0.7333, valid_waf1: 0.6303637623786926, test_waf1: 0.6489906907081604
==========Epoch: 6 ==============
Epoch: 6, train_loss: 0.7225, valid_waf1: 0.6341946721076965, test_waf1: 0.6569503545761108
==========Epoch: 7 ==============
Epoch: 7, train_loss: 0.7095, valid_waf1: 0.6375202536582947, test_waf1: 0.6569168567657471
==========Epoch: 8 ==============
Epoch: 8, train_loss: 0.7089, valid_waf1: 0.6432786583900452, test_waf1: 0.6544406414031982
==========Epoch: 9 ==============
Epoch: 9, train_loss: 0.7001, valid_waf1: 0.6386275887489319, test_waf1: 0.658318281173706
==========Epoch: 10 ==============
Epoch: 10, train_loss: 0.703, valid_waf1: 0.6424942016601562, test_waf1: 0.6571750044822693
==========Epoch: 11 ==============
Epoch: 11, train_loss: 0.6976, valid_waf1: 0.6451978087425232, test_waf1: 0.6622149348258972
==========Epoch: 12 ==============
Epoch: 12, train_loss: 0.6942, valid_waf1: 0.6409860253334045, test_waf1: 0.6619259715080261
==========Epoch: 13 ==============
Epoch: 13, train_loss: 0.6903, valid_waf1: 0.6464006304740906, test_waf1: 0.6555883288383484
==========Epoch: 14 ==============
Epoch: 14, train_loss: 0.6896, valid_waf1: 0.6448454856872559, test_waf1: 0.6636589169502258
==========Epoch: 15 ==============
Epoch: 15, train_loss: 0.6878, valid_waf1: 0.6508516073226929, test_waf1: 0.6635786890983582
==========Epoch: 16 ==============
Epoch: 16, train_loss: 0.6767, valid_waf1: 0.6409115791320801, test_waf1: 0.6576259136199951
==========Epoch: 17 ==============
Epoch: 17, train_loss: 0.6756, valid_waf1: 0.6497839689254761, test_waf1: 0.6654347777366638
==========Epoch: 18 ==============
Epoch: 18, train_loss: 0.6815, valid_waf1: 0.6620883941650391, test_waf1: 0.6676478385925293
==========Epoch: 19 ==============
Epoch: 19, train_loss: 0.6746, valid_waf1: 0.6449135541915894, test_waf1: 0.6688258647918701
==========Epoch: 20 ==============
Epoch: 20, train_loss: 0.6728, valid_waf1: 0.6568037867546082, test_waf1: 0.6682528257369995
==========Epoch: 21 ==============
Epoch: 21, train_loss: 0.6838, valid_waf1: 0.6515166759490967, test_waf1: 0.6684510707855225
==========Epoch: 22 ==============
Epoch: 22, train_loss: 0.6695, valid_waf1: 0.6636691689491272, test_waf1: 0.6722615957260132
==========Epoch: 23 ==============
Epoch: 23, train_loss: 0.666, valid_waf1: 0.6558282375335693, test_waf1: 0.66512131690979
==========Epoch: 24 ==============
Epoch: 24, train_loss: 0.6665, valid_waf1: 0.6596952676773071, test_waf1: 0.6675010919570923
==========Epoch: 25 ==============
Epoch: 25, train_loss: 0.666, valid_waf1: 0.6633766889572144, test_waf1: 0.6683899760246277
==========Epoch: 26 ==============
Epoch: 26, train_loss: 0.6594, valid_waf1: 0.6657952666282654, test_waf1: 0.6724042892456055
==========Epoch: 27 ==============
Epoch: 27, train_loss: 0.6608, valid_waf1: 0.6594537496566772, test_waf1: 0.6650639772415161
==========Epoch: 28 ==============
Epoch: 28, train_loss: 0.6603, valid_waf1: 0.6578115224838257, test_waf1: 0.6665851473808289
==========Epoch: 29 ==============
Epoch: 29, train_loss: 0.6569, valid_waf1: 0.6639404892921448, test_waf1: 0.6717599630355835
==========Epoch: 30 ==============
Epoch: 30, train_loss: 0.6556, valid_waf1: 0.6579384207725525, test_waf1: 0.6668462753295898
==========Epoch: 31 ==============
Epoch: 31, train_loss: 0.6498, valid_waf1: 0.6592467427253723, test_waf1: 0.6659743189811707
==========Epoch: 32 ==============
Epoch: 32, train_loss: 0.6541, valid_waf1: 0.6674184203147888, test_waf1: 0.6671725511550903
==========Epoch: 33 ==============
Epoch: 33, train_loss: 0.6555, valid_waf1: 0.6655332446098328, test_waf1: 0.6705343723297119
==========Epoch: 34 ==============
Epoch: 34, train_loss: 0.6477, valid_waf1: 0.656526505947113, test_waf1: 0.6611983180046082
==========Epoch: 35 ==============
Epoch: 35, train_loss: 0.6483, valid_waf1: 0.6615126132965088, test_waf1: 0.6724590063095093
==========Epoch: 36 ==============
Epoch: 36, train_loss: 0.6509, valid_waf1: 0.6645805835723877, test_waf1: 0.6674875617027283
==========Epoch: 37 ==============
Epoch: 37, train_loss: 0.6517, valid_waf1: 0.6606007814407349, test_waf1: 0.6686582565307617
==========Epoch: 38 ==============
Epoch: 38, train_loss: 0.6515, valid_waf1: 0.6675490140914917, test_waf1: 0.6702689528465271
==========Epoch: 39 ==============
Epoch: 39, train_loss: 0.6389, valid_waf1: 0.6618070006370544, test_waf1: 0.666731595993042
==========Epoch: 40 ==============
Epoch: 40, train_loss: 0.6446, valid_waf1: 0.6625775694847107, test_waf1: 0.6678275465965271
==========Epoch: 41 ==============
Epoch: 41, train_loss: 0.6455, valid_waf1: 0.6600884199142456, test_waf1: 0.6700561046600342
==========Epoch: 42 ==============
Epoch: 42, train_loss: 0.64, valid_waf1: 0.6554110050201416, test_waf1: 0.6688284873962402
==========Epoch: 43 ==============
Epoch: 43, train_loss: 0.6413, valid_waf1: 0.6600001454353333, test_waf1: 0.6697919368743896
==========Epoch: 44 ==============
Epoch: 44, train_loss: 0.6435, valid_waf1: 0.6580075025558472, test_waf1: 0.667952299118042
==========Epoch: 45 ==============
Epoch: 45, train_loss: 0.6352, valid_waf1: 0.6591352820396423, test_waf1: 0.6717000603675842
==========Epoch: 46 ==============
Epoch: 46, train_loss: 0.6363, valid_waf1: 0.6676989793777466, test_waf1: 0.6764808297157288
==========Epoch: 47 ==============
Epoch: 47, train_loss: 0.6388, valid_waf1: 0.6621015071868896, test_waf1: 0.67440265417099
==========Epoch: 48 ==============
Epoch: 48, train_loss: 0.635, valid_waf1: 0.6665893793106079, test_waf1: 0.675814151763916
==========Epoch: 49 ==============
Epoch: 49, train_loss: 0.6338, valid_waf1: 0.6591632962226868, test_waf1: 0.6757997870445251
==========Epoch: 50 ==============
Epoch: 50, train_loss: 0.6286, valid_waf1: 0.6567525267601013, test_waf1: 0.6771847605705261
The best dev set WA.F1:0.6676989793777466
************final performance on test set************
The corresponding test set WA.F1 when the dev set WA.F1 is the best:0.6764808297157288
finish training!
