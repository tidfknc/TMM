nohup: ignoring input
Namespace(batch_size=16, dataset_name='IEMOCAP', epochs=50, gnn_layers=4, hidden_dim=300, lr=0.0005, mlp_layers=2, modality='tav', tau=0.2)
device: cuda
building model..
building datasets..
train dialogue num:
108
train utterance num:
5163
building datasets..
dev dialogue num:
12
dev utterance num:
647
building datasets..
test dialogue num:
31
test utterance num:
1623
==========Epoch: 1 ==============
Epoch: 1, train_loss: 1.6399, valid_waf1: 0.2908397316932678, test_waf1: 0.3743516206741333
==========Epoch: 2 ==============
Epoch: 2, train_loss: 1.1943, valid_waf1: 0.42719119787216187, test_waf1: 0.46347811818122864
==========Epoch: 3 ==============
Epoch: 3, train_loss: 1.0339, valid_waf1: 0.5026176571846008, test_waf1: 0.5389610528945923
==========Epoch: 4 ==============
Epoch: 4, train_loss: 0.9194, valid_waf1: 0.5329904556274414, test_waf1: 0.5732454061508179
==========Epoch: 5 ==============
Epoch: 5, train_loss: 0.8548, valid_waf1: 0.48023244738578796, test_waf1: 0.5718122720718384
==========Epoch: 6 ==============
Epoch: 6, train_loss: 0.8254, valid_waf1: 0.5751563906669617, test_waf1: 0.6131752729415894
==========Epoch: 7 ==============
Epoch: 7, train_loss: 0.7822, valid_waf1: 0.5157660245895386, test_waf1: 0.5867851972579956
==========Epoch: 8 ==============
Epoch: 8, train_loss: 0.7681, valid_waf1: 0.5701748728752136, test_waf1: 0.6080660820007324
==========Epoch: 9 ==============
Epoch: 9, train_loss: 0.7302, valid_waf1: 0.5653003454208374, test_waf1: 0.6182488799095154
==========Epoch: 10 ==============
Epoch: 10, train_loss: 0.7255, valid_waf1: 0.6058334112167358, test_waf1: 0.6358359456062317
==========Epoch: 11 ==============
Epoch: 11, train_loss: 0.7066, valid_waf1: 0.605448842048645, test_waf1: 0.6261637210845947
==========Epoch: 12 ==============
Epoch: 12, train_loss: 0.691, valid_waf1: 0.5733059644699097, test_waf1: 0.6348978281021118
==========Epoch: 13 ==============
Epoch: 13, train_loss: 0.7154, valid_waf1: 0.5654451847076416, test_waf1: 0.6182940006256104
==========Epoch: 14 ==============
Epoch: 14, train_loss: 0.6505, valid_waf1: 0.5936949253082275, test_waf1: 0.657055139541626
==========Epoch: 15 ==============
Epoch: 15, train_loss: 0.6679, valid_waf1: 0.6278368830680847, test_waf1: 0.6474820375442505
==========Epoch: 16 ==============
Epoch: 16, train_loss: 0.6746, valid_waf1: 0.5979077816009521, test_waf1: 0.6386911869049072
==========Epoch: 17 ==============
Epoch: 17, train_loss: 0.635, valid_waf1: 0.5829078555107117, test_waf1: 0.6558707356452942
==========Epoch: 18 ==============
Epoch: 18, train_loss: 0.6312, valid_waf1: 0.6186952590942383, test_waf1: 0.6703301668167114
==========Epoch: 19 ==============
Epoch: 19, train_loss: 0.5976, valid_waf1: 0.6045985221862793, test_waf1: 0.6499552726745605
==========Epoch: 20 ==============
Epoch: 20, train_loss: 0.5792, valid_waf1: 0.6022586822509766, test_waf1: 0.6546283960342407
==========Epoch: 21 ==============
Epoch: 21, train_loss: 0.5778, valid_waf1: 0.6200708150863647, test_waf1: 0.6588753461837769
==========Epoch: 22 ==============
Epoch: 22, train_loss: 0.5706, valid_waf1: 0.5904955267906189, test_waf1: 0.6676942110061646
==========Epoch: 23 ==============
Epoch: 23, train_loss: 0.5434, valid_waf1: 0.5981571078300476, test_waf1: 0.6850708723068237
==========Epoch: 24 ==============
Epoch: 24, train_loss: 0.5508, valid_waf1: 0.5924692153930664, test_waf1: 0.671651303768158
==========Epoch: 25 ==============
Epoch: 25, train_loss: 0.5442, valid_waf1: 0.5912742018699646, test_waf1: 0.6835814118385315
==========Epoch: 26 ==============
Epoch: 26, train_loss: 0.5104, valid_waf1: 0.5890716314315796, test_waf1: 0.6818186640739441
==========Epoch: 27 ==============
Epoch: 27, train_loss: 0.5275, valid_waf1: 0.6053026914596558, test_waf1: 0.6656230688095093
==========Epoch: 28 ==============
Epoch: 28, train_loss: 0.4923, valid_waf1: 0.5944819450378418, test_waf1: 0.6763849258422852
==========Epoch: 29 ==============
Epoch: 29, train_loss: 0.5307, valid_waf1: 0.5838530659675598, test_waf1: 0.6803461313247681
==========Epoch: 30 ==============
Epoch: 30, train_loss: 0.5124, valid_waf1: 0.6150810718536377, test_waf1: 0.6958234310150146
==========Epoch: 31 ==============
Epoch: 31, train_loss: 0.4861, valid_waf1: 0.6207623481750488, test_waf1: 0.6842260360717773
==========Epoch: 32 ==============
Epoch: 32, train_loss: 0.4728, valid_waf1: 0.6079481244087219, test_waf1: 0.6954649686813354
==========Epoch: 33 ==============
Epoch: 33, train_loss: 0.4747, valid_waf1: 0.6307235956192017, test_waf1: 0.6687975525856018
==========Epoch: 34 ==============
Epoch: 34, train_loss: 0.4667, valid_waf1: 0.642989456653595, test_waf1: 0.6982330083847046
==========Epoch: 35 ==============
Epoch: 35, train_loss: 0.4593, valid_waf1: 0.611242949962616, test_waf1: 0.6930373907089233
==========Epoch: 36 ==============
Epoch: 36, train_loss: 0.4642, valid_waf1: 0.5988130569458008, test_waf1: 0.6555006504058838
==========Epoch: 37 ==============
Epoch: 37, train_loss: 0.4472, valid_waf1: 0.607656717300415, test_waf1: 0.6630246639251709
==========Epoch: 38 ==============
Epoch: 38, train_loss: 0.4361, valid_waf1: 0.6510262489318848, test_waf1: 0.6823748350143433
==========Epoch: 39 ==============
Epoch: 39, train_loss: 0.4101, valid_waf1: 0.6409656405448914, test_waf1: 0.7009637355804443
==========Epoch: 40 ==============
Epoch: 40, train_loss: 0.3871, valid_waf1: 0.6378291845321655, test_waf1: 0.705243706703186
==========Epoch: 41 ==============
Epoch: 41, train_loss: 0.3686, valid_waf1: 0.6703037023544312, test_waf1: 0.7143898606300354
==========Epoch: 42 ==============
Epoch: 42, train_loss: 0.3769, valid_waf1: 0.6382793188095093, test_waf1: 0.7073004245758057
==========Epoch: 43 ==============
Epoch: 43, train_loss: 0.3543, valid_waf1: 0.6324549317359924, test_waf1: 0.7009976506233215
==========Epoch: 44 ==============
Epoch: 44, train_loss: 0.3641, valid_waf1: 0.6623234748840332, test_waf1: 0.6933410167694092
==========Epoch: 45 ==============
Epoch: 45, train_loss: 0.3314, valid_waf1: 0.6500605344772339, test_waf1: 0.6958445310592651
==========Epoch: 46 ==============
Epoch: 46, train_loss: 0.344, valid_waf1: 0.6301610469818115, test_waf1: 0.6774191856384277
==========Epoch: 47 ==============
Epoch: 47, train_loss: 0.3359, valid_waf1: 0.6354779005050659, test_waf1: 0.678856611251831
==========Epoch: 48 ==============
Epoch: 48, train_loss: 0.3466, valid_waf1: 0.6560544967651367, test_waf1: 0.6680809855461121
==========Epoch: 49 ==============
Epoch: 49, train_loss: 0.3661, valid_waf1: 0.6458930373191833, test_waf1: 0.6917417049407959
==========Epoch: 50 ==============
Epoch: 50, train_loss: 0.3307, valid_waf1: 0.6283940076828003, test_waf1: 0.6990872621536255
The best dev set WA.F1:0.6703037023544312
************final performance on test set************
The corresponding test set WA.F1 when the dev set WA.F1 is the best:0.7143898606300354
finish training!
