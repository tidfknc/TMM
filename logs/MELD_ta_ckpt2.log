nohup: ignoring input
Namespace(batch_size=64, dataset_name='MELD', epochs=50, gnn_layers=5, hidden_dim=600, lr=5e-05, mlp_layers=2, modality='ta', tau=1.0)
device: cuda
building model..
building datasets..
train dialogue num:
1038
train utterance num:
9989
building datasets..
dev dialogue num:
114
dev utterance num:
1109
building datasets..
test dialogue num:
280
test utterance num:
2610
==========Epoch: 1 ==============
Epoch: 1, train_loss: 1.5633, valid_waf1: 0.25229698419570923, test_waf1: 0.31268492341041565
==========Epoch: 2 ==============
Epoch: 2, train_loss: 1.1324, valid_waf1: 0.5520688891410828, test_waf1: 0.6005820631980896
==========Epoch: 3 ==============
Epoch: 3, train_loss: 0.8585, valid_waf1: 0.6231793761253357, test_waf1: 0.6415181159973145
==========Epoch: 4 ==============
Epoch: 4, train_loss: 0.7633, valid_waf1: 0.6418299674987793, test_waf1: 0.6498979926109314
==========Epoch: 5 ==============
Epoch: 5, train_loss: 0.7333, valid_waf1: 0.6303637623786926, test_waf1: 0.6489906907081604
==========Epoch: 6 ==============
Epoch: 6, train_loss: 0.7225, valid_waf1: 0.6341946721076965, test_waf1: 0.6569503545761108
==========Epoch: 7 ==============
Epoch: 7, train_loss: 0.7096, valid_waf1: 0.6375202536582947, test_waf1: 0.65651935338974
==========Epoch: 8 ==============
Epoch: 8, train_loss: 0.7089, valid_waf1: 0.644862174987793, test_waf1: 0.6540228724479675
==========Epoch: 9 ==============
Epoch: 9, train_loss: 0.7, valid_waf1: 0.6386275887489319, test_waf1: 0.6579043865203857
==========Epoch: 10 ==============
Epoch: 10, train_loss: 0.7029, valid_waf1: 0.6415367722511292, test_waf1: 0.6568635106086731
==========Epoch: 11 ==============
Epoch: 11, train_loss: 0.6976, valid_waf1: 0.6451978087425232, test_waf1: 0.6615891456604004
==========Epoch: 12 ==============
Epoch: 12, train_loss: 0.6942, valid_waf1: 0.6410574316978455, test_waf1: 0.6623368859291077
==========Epoch: 13 ==============
Epoch: 13, train_loss: 0.6903, valid_waf1: 0.6444207429885864, test_waf1: 0.6559913754463196
==========Epoch: 14 ==============
Epoch: 14, train_loss: 0.6895, valid_waf1: 0.644119918346405, test_waf1: 0.6632283329963684
==========Epoch: 15 ==============
Epoch: 15, train_loss: 0.6878, valid_waf1: 0.6508315205574036, test_waf1: 0.6635465025901794
==========Epoch: 16 ==============
Epoch: 16, train_loss: 0.6766, valid_waf1: 0.6401384472846985, test_waf1: 0.6585439443588257
==========Epoch: 17 ==============
Epoch: 17, train_loss: 0.6757, valid_waf1: 0.6453311443328857, test_waf1: 0.665043830871582
==========Epoch: 18 ==============
Epoch: 18, train_loss: 0.6813, valid_waf1: 0.6614177227020264, test_waf1: 0.6666092872619629
==========Epoch: 19 ==============
Epoch: 19, train_loss: 0.6745, valid_waf1: 0.6449133157730103, test_waf1: 0.6696500182151794
==========Epoch: 20 ==============
Epoch: 20, train_loss: 0.6727, valid_waf1: 0.6574915051460266, test_waf1: 0.6682528257369995
==========Epoch: 21 ==============
Epoch: 21, train_loss: 0.6837, valid_waf1: 0.6525239944458008, test_waf1: 0.668113112449646
==========Epoch: 22 ==============
Epoch: 22, train_loss: 0.6694, valid_waf1: 0.6622706651687622, test_waf1: 0.6722000241279602
==========Epoch: 23 ==============
Epoch: 23, train_loss: 0.6659, valid_waf1: 0.6573553085327148, test_waf1: 0.6651116013526917
==========Epoch: 24 ==============
Epoch: 24, train_loss: 0.6664, valid_waf1: 0.659827470779419, test_waf1: 0.6669149994850159
==========Epoch: 25 ==============
Epoch: 25, train_loss: 0.6661, valid_waf1: 0.6646333336830139, test_waf1: 0.6691820025444031
==========Epoch: 26 ==============
Epoch: 26, train_loss: 0.6593, valid_waf1: 0.6648094058036804, test_waf1: 0.6715027093887329
==========Epoch: 27 ==============
Epoch: 27, train_loss: 0.6607, valid_waf1: 0.658333957195282, test_waf1: 0.6654653549194336
==========Epoch: 28 ==============
Epoch: 28, train_loss: 0.6603, valid_waf1: 0.6561598181724548, test_waf1: 0.6655431985855103
==========Epoch: 29 ==============
Epoch: 29, train_loss: 0.6567, valid_waf1: 0.6657993793487549, test_waf1: 0.6738556623458862
==========Epoch: 30 ==============
Epoch: 30, train_loss: 0.6554, valid_waf1: 0.6578518152236938, test_waf1: 0.6662987470626831
==========Epoch: 31 ==============
Epoch: 31, train_loss: 0.6497, valid_waf1: 0.6592467427253723, test_waf1: 0.6657055616378784
==========Epoch: 32 ==============
Epoch: 32, train_loss: 0.6539, valid_waf1: 0.6692672967910767, test_waf1: 0.6689796447753906
==========Epoch: 33 ==============
Epoch: 33, train_loss: 0.6552, valid_waf1: 0.6642426252365112, test_waf1: 0.6694687604904175
==========Epoch: 34 ==============
Epoch: 34, train_loss: 0.6478, valid_waf1: 0.6566778421401978, test_waf1: 0.6615689992904663
==========Epoch: 35 ==============
Epoch: 35, train_loss: 0.6484, valid_waf1: 0.6638175249099731, test_waf1: 0.6708275675773621
==========Epoch: 36 ==============
Epoch: 36, train_loss: 0.6507, valid_waf1: 0.6633096933364868, test_waf1: 0.6674208641052246
==========Epoch: 37 ==============
Epoch: 37, train_loss: 0.6515, valid_waf1: 0.661248505115509, test_waf1: 0.6697434186935425
==========Epoch: 38 ==============
Epoch: 38, train_loss: 0.6514, valid_waf1: 0.6695577502250671, test_waf1: 0.672155499458313
==========Epoch: 39 ==============
Epoch: 39, train_loss: 0.639, valid_waf1: 0.6620228886604309, test_waf1: 0.6693916916847229
==========Epoch: 40 ==============
Epoch: 40, train_loss: 0.6445, valid_waf1: 0.6627626419067383, test_waf1: 0.6671411991119385
==========Epoch: 41 ==============
Epoch: 41, train_loss: 0.6457, valid_waf1: 0.6626012325286865, test_waf1: 0.6684398055076599
==========Epoch: 42 ==============
Epoch: 42, train_loss: 0.6398, valid_waf1: 0.6531574130058289, test_waf1: 0.6676724553108215
==========Epoch: 43 ==============
Epoch: 43, train_loss: 0.6412, valid_waf1: 0.6615620851516724, test_waf1: 0.6697412729263306
==========Epoch: 44 ==============
Epoch: 44, train_loss: 0.6435, valid_waf1: 0.659728467464447, test_waf1: 0.6669207215309143
==========Epoch: 45 ==============
Epoch: 45, train_loss: 0.6349, valid_waf1: 0.6577003002166748, test_waf1: 0.6724259853363037
==========Epoch: 46 ==============
Epoch: 46, train_loss: 0.6365, valid_waf1: 0.6680673360824585, test_waf1: 0.6775120496749878
==========Epoch: 47 ==============
Epoch: 47, train_loss: 0.6388, valid_waf1: 0.6592516303062439, test_waf1: 0.6729748249053955
==========Epoch: 48 ==============
Epoch: 48, train_loss: 0.6347, valid_waf1: 0.6633309125900269, test_waf1: 0.6752495169639587
==========Epoch: 49 ==============
Epoch: 49, train_loss: 0.6337, valid_waf1: 0.6608986258506775, test_waf1: 0.6746052503585815
==========Epoch: 50 ==============
Epoch: 50, train_loss: 0.6286, valid_waf1: 0.6546099781990051, test_waf1: 0.6773532629013062
The best dev set WA.F1:0.6695577502250671
************final performance on test set************
The corresponding test set WA.F1 when the dev set WA.F1 is the best:0.672155499458313
finish training!
